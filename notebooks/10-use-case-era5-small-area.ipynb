{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a76c0b-7859-4d3e-a29a-4909dc9cc62c",
   "metadata": {},
   "source": [
    "# Use case: ERA5 small area \n",
    "\n",
    "Earth Data Hub offers an innovative and super-efficient way to access data.\n",
    "\n",
    "Here we present how to best access the service in the simplest use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec421c5-303b-45ae-a61e-342117a1e576",
   "metadata": {},
   "source": [
    "## Setup the environment\n",
    "\n",
    "If you haven't done it already, follow the [Getting started notebook](./00-getting-started.ipynb) to setup your environment and DestinE credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4213e65-e0ba-40f2-9272-8fe692e52981",
   "metadata": {},
   "source": [
    "## Download 30 years of an ERA5 variable on a small area\n",
    "\n",
    "Our use case is to compute various climatological averages of one ERA5 variable over a long period of time, e.g. the surface temperature over 30 years. Note that we will be  using the ERA5 single levels dataset that has more than 100 variable and every variable is almost 3TB in size. \n",
    "\n",
    "The best practice for downloading data form the Earth Data Hub comprise the following steps:\n",
    "1. open the dataset using the code snippet found on the [ERA5 dataset page](https://earthdatahub.destine.eu/collections/era5/datasets/reanalysis-era5-single-levels)\n",
    "2. select (and optionally prepare) the variable\n",
    "3. select the area of interest (optionally alligning it on chunk boundaries)\n",
    "4. select the time interval of interest\n",
    "5. download the data to memory (with `.persist()` or `.compute()`)\n",
    "6. save the data or compute the result in memory\n",
    "\n",
    "### Open the dataset\n",
    "\n",
    "The following assumes you set up the EDH Personal Access Token in your _netrc_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fbb516-13f5-4953-8f22-b6a7fba7fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "era5_single_levels_dataset = xr.open_dataset(\n",
    "    \"https://data.earthdatahub.destine.eu/era5/reanalysis-era5-single-levels-v0.zarr\",\n",
    "    storage_options={\"client_kwargs\": {\"trust_env\": True}},\n",
    "    chunks={},\n",
    "    engine=\"zarr\",\n",
    ")\n",
    "era5_single_levels_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f0d2d-140b-4099-9eee-3f9cb2f16697",
   "metadata": {},
   "source": [
    "### Select and prepare the variable\n",
    "\n",
    "Note that all operation are lazy, that is are not applied to the whole 3TB of data, but are just recorded fror later use. Download and computations are only done when requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a4467-021d-40d6-8047-f82bf599350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_world = era5_single_levels_dataset.t2m - 273.15\n",
    "t2m_world.attrs[\"units\"] = \"Â°C\"\n",
    "t2m_world.attrs[\"long_name\"] = \"surface air temperature\"\n",
    "t2m_world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b078f02d-27c9-4c01-9a23-4fed295bd637",
   "metadata": {},
   "source": [
    "### Select the area of interest\n",
    "\n",
    "For example we are interested in the area of the Alps.\n",
    "\n",
    "This a very convenient example as:\n",
    "* it is a large enough area to be more interesting than a time-series of a single point,\n",
    "* it is small enough to fit a single Zarr chunk, so the notebook can be run even with a slow internet connection,\n",
    "* when plotted it is easy to identify even without adding coastlines and country borders that will make the notebook more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252de398-c163-441f-9adc-0eef347f0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_selection = {\n",
    "    \"latitude\": slice(49, 43),  # NOTE: ERA5 has a descending latitude coordinate\n",
    "    \"longitude\": slice(5, 15),\n",
    "}\n",
    "t2m_aoi = t2m_world.sel(aoi_selection)\n",
    "t2m_aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f09ade-9c63-4300-b90d-8976039e1507",
   "metadata": {},
   "source": [
    "Note that the data size is not much smaller, we went from 3TB for global data to 3GB of our small area of interest.\n",
    "\n",
    "We plot the map of the temperature at one time to double check that the selection is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ad95a-b980-457d-8032-a5c34d14ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_aoi.sel(valid_time=\"2020-01-01T00:00:00\").plot(vmin=-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b0bb2-1666-4819-a4b9-51f17c5063db",
   "metadata": {},
   "source": [
    "### Optional: allign the area of interest on chunk boundaries\n",
    "\n",
    "This a pro move and you can skip it.\n",
    "\n",
    "When accessing the data in Zarr you always dowload whole chunks, even if you are only interestind in part of them. In the case of EAR5 single level the spatial chunks are `(64, 64)` in size and even if you can read above that your DataArray in only 2GB of data you are most probably donwloading more data and then throuing a part of it away.\n",
    "\n",
    "You can use the following (not very nice) code to grow your area of interest to the bounderies of the Zarr chunks, so you use all the data you donwload. Note that now you also have the size of the data that would be downloaded is it was not compressed (the data is in fact compressed so actual downlaod is smaller)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b8371-3405-4616-a336-49a89ccf0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_indexer(step, indexer):\n",
    "    if not isinstance(indexer, slice):\n",
    "        return indexer\n",
    "    assert indexer.step is None\n",
    "    start = indexer.start // step * step if indexer.start else indexer.start\n",
    "    stop = (indexer.stop // step + 1) * step if indexer.stop else indexer.stop\n",
    "    return slice(start, stop)\n",
    "\n",
    "\n",
    "query_results = xr.core.indexing.map_index_queries(\n",
    "    t2m_world, indexers=aoi_selection, method=None, tolerance=None\n",
    ")\n",
    "print(query_results.dim_indexers)\n",
    "\n",
    "aoi_iselection = {\n",
    "    dim: align_indexer(64, query_results.dim_indexers[dim])\n",
    "    for dim in query_results.dim_indexers\n",
    "}\n",
    "print(aoi_iselection)\n",
    "\n",
    "t2m_aoi = t2m_world.isel(aoi_iselection)\n",
    "t2m_aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b20c36-efa9-4c28-9dbe-189260755179",
   "metadata": {},
   "source": [
    "So, the full time-series for a whole chunk is really 11.5GB, not 2GB.\n",
    "\n",
    "Let's have a look at the area of the whole chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c6eff-c5c8-4188-a226-3ed68e80ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_aoi.sel(valid_time=\"2020-01-01T00:00:00\").plot(vmin=-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b2dbe-7839-426b-981b-f765e7659c38",
   "metadata": {},
   "source": [
    "### Select the time interval of iterest\n",
    "\n",
    "We take one of the typical 30 year periods to compute climatologies and finally we have a definition of the data we want to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07975593-d5ff-4e9d-ab3b-36b8cf72d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_aoi_toi = t2m_aoi.sel(valid_time=slice(\"1981\", \"2010\"))\n",
    "t2m_aoi_toi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7397f-b58b-43ca-8a1b-951dbdbdc0bd",
   "metadata": {},
   "source": [
    "From the representation above we learn a few things:\n",
    "1. the uncompressed data to be downloaded, e.g. 4GB (compression depends on the dataset and the variable)\n",
    "2. the number of chunks to be downlaoded, e.g. 62\n",
    "\n",
    "### Download the data to memory\n",
    "\n",
    "Finally we are ready to download only the data that we are interested in in memory.\n",
    "\n",
    "The best practice is to use `.persist()` to trigger the laod into the Dask memory, this is an advantage in the following computations and expecially if you use a Dask cluster. The following `.compute()` is there only to wait until the downalod finisched so we can time it.\n",
    "\n",
    "**This operation is the slow one. It takes up to 20 minutes on a 8 Mbps connection.**\n",
    "\n",
    "It depends on the download speed of your intenet connection and on the load on the Earth Data Hub. The closer you are to the data the faster it is, and this is one of the reason the EDH is best suited to be used from within the DestinE platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d049c8e-3a19-42cc-8569-671001bacc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t2m_aoi_toi = t2m_aoi_toi.persist()  # this triggers the download without bloccking\n",
    "_ = t2m_aoi_toi.compute()  # this blocks until data is persisted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335f7d2-5cd4-4ad1-8e6c-3eaebe9aafa2",
   "metadata": {},
   "source": [
    "### Perform any computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c39ca-79c3-41d6-bc52-e1d34cc5ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t2m_aoi_toi_month_mean = t2m_aoi_toi.groupby(\"valid_time.month\").mean().compute()\n",
    "t2m_aoi_toi_month_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64b040-4a8a-49c4-b1fe-35f7da1af5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_aoi_toi_month_mean.plot(vmin=-30, col=\"month\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbedc7cb-8e4a-4580-8e6e-8e52adca4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t2m_aoi_toi_doy_mean = t2m_aoi_toi.groupby(\"valid_time.dayofyear\").mean().compute()\n",
    "t2m_aoi_toi_doy_mean = t2m_aoi_toi_doy_mean.sel(dayofyear=slice(0, 365))\n",
    "t2m_aoi_toi_doy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720476a-fa24-4767-91ca-e44c7fb0f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_aoi_toi_doy_mean.sel(latitude=46.5, longitude=11.8, method=\"nearest\").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a81af1-3ced-4764-9548-5fdc9482d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t2m_aoi_toi_doy_quantile = (\n",
    "    t2m_aoi_toi.groupby(\"valid_time.dayofyear\").quantile([0.9, 0.5, 0.1]).compute()\n",
    ")\n",
    "t2m_aoi_toi_doy_quantile = t2m_aoi_toi_doy_quantile.sel(dayofyear=slice(0, 365))\n",
    "t2m_aoi_toi_doy_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90f2a2-6b98-4edc-b329-21f32ffdfd19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
